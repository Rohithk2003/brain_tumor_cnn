{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-14T06:40:58.675590740Z",
     "start_time": "2024-01-14T06:40:58.661990316Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-14 12:10:58.625218: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-14 12:10:58.658626: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-14 12:10:58.658863: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from PIL import Image, ImageEnhance\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.losses import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.metrics import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.applications import *\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout\n",
    "# from tensorflow.keras.optimizers.legacy import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "import os\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-14T06:40:58.676436870Z",
     "start_time": "2024-01-14T06:40:58.665796027Z"
    }
   },
   "outputs": [],
   "source": [
    "def augment_image(image):\n",
    "    image = Image.fromarray(np.uint8(image))\n",
    "    image = ImageEnhance.Brightness(image).enhance(random.uniform(0.8,1.2))\n",
    "    image = ImageEnhance.Contrast(image).enhance(random.uniform(0.8,1.2))\n",
    "    image = ImageEnhance.Sharpness(image).enhance(random.uniform(0.8,1.2))\n",
    "    image = np.array(image)/255.0\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-14T06:40:58.710890052Z",
     "start_time": "2024-01-14T06:40:58.671910138Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data_path = 'Training/'\n",
    "filepaths =[]\n",
    "labels = []\n",
    "import pandas as pd\n",
    "import os\n",
    "folds = os.listdir(train_data_path)\n",
    "\n",
    "for fold in folds:\n",
    "    f_path = os.path.join(train_data_path , fold)\n",
    "    filelists = os.listdir(f_path)\n",
    "    \n",
    "    for file in filelists:\n",
    "        filepaths.append(os.path.join(f_path , file))\n",
    "        labels.append(fold)\n",
    "        \n",
    "#Concat data paths with labels\n",
    "Fseries = pd.Series(filepaths , name = 'filepaths')\n",
    "Lseries = pd.Series(labels , name = 'label')\n",
    "train_df = pd.concat([Fseries , Lseries] , axis = 1)\n",
    "test_data_path = 'Testing/'\n",
    "filepaths =[]\n",
    "labels = []\n",
    "\n",
    "folds = os.listdir(test_data_path)\n",
    "\n",
    "for fold in folds:\n",
    "    f_path = os.path.join(test_data_path , fold)\n",
    "    filelists = os.listdir(f_path)\n",
    "    \n",
    "    for file in filelists:\n",
    "        filepaths.append(os.path.join(f_path , file))\n",
    "        labels.append(fold)\n",
    "        \n",
    "Fseries = pd.Series(filepaths , name = 'filepaths')\n",
    "Lseries = pd.Series(labels , name = 'label')\n",
    "test_df = pd.concat([Fseries , Lseries] , axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-14T06:40:58.737773088Z",
     "start_time": "2024-01-14T06:40:58.689313338Z"
    }
   },
   "outputs": [],
   "source": [
    "valid , test = train_test_split(test_df , train_size = 0.8, shuffle = True , random_state= 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-14T06:40:58.739692293Z",
     "start_time": "2024-01-14T06:40:58.737773148Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5712 validated image filenames belonging to 4 classes.\n",
      "Found 1048 validated image filenames belonging to 4 classes.\n",
      "Found 263 validated image filenames belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "img_size = (224, 244)\n",
    "batch_size = 32\n",
    "\n",
    "tr_gen = ImageDataGenerator(\n",
    ")\n",
    "ts_gen = ImageDataGenerator(\n",
    ")\n",
    "\n",
    "train_gen = tr_gen.flow_from_dataframe(\n",
    "    train_df,\n",
    "    x_col=\"filepaths\",\n",
    "    y_col=\"label\",\n",
    "    target_size=img_size,\n",
    "    class_mode=\"categorical\",\n",
    "    color_mode=\"rgb\",\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "valid_gen = ts_gen.flow_from_dataframe(\n",
    "    valid,\n",
    "    x_col=\"filepaths\",\n",
    "    y_col=\"label\",\n",
    "    target_size=img_size,\n",
    "    class_mode=\"categorical\",\n",
    "    color_mode=\"rgb\",\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "test_gen = ts_gen.flow_from_dataframe(\n",
    "    test,\n",
    "    x_col=\"filepaths\",\n",
    "    y_col=\"label\",\n",
    "    target_size=img_size,\n",
    "    class_mode=\"categorical\",\n",
    "    color_mode=\"rgb\",\n",
    "    shuffle=False,\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-14T06:46:43.578842755Z",
     "start_time": "2024-01-14T06:40:58.781421415Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-14 12:10:58.755683: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-14 12:10:58.756045: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-14 12:10:58.756292: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-14 12:10:58.824181: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-14 12:10:58.824513: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-14 12:10:58.824734: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-14 12:10:58.824883: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1599 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2050, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2024-01-14 12:10:59.018184: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-14 12:11:03.833180: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f8a68f5e700 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-01-14 12:11:03.833215: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 2050, Compute Capability 8.6\n",
      "2024-01-14 12:11:03.837173: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1705214463.908244   37510 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2024-01-14 12:11:07.981204: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.05GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-01-14 12:11:08.393176: W external/local_tsl/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.05GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 33s 127ms/step - loss: 0.8254 - accuracy: 0.6628 - val_loss: 0.6681 - val_accuracy: 0.7223\n",
      "Epoch 2/20\n",
      "178/178 [==============================] - 16s 90ms/step - loss: 0.4020 - accuracy: 0.8442 - val_loss: 0.4096 - val_accuracy: 0.8225\n",
      "Epoch 3/20\n",
      "178/178 [==============================] - 15s 84ms/step - loss: 0.2968 - accuracy: 0.8899 - val_loss: 0.2549 - val_accuracy: 0.8989\n",
      "Epoch 4/20\n",
      "178/178 [==============================] - 15s 84ms/step - loss: 0.1888 - accuracy: 0.9333 - val_loss: 0.1802 - val_accuracy: 0.9399\n",
      "Epoch 5/20\n",
      "178/178 [==============================] - 15s 84ms/step - loss: 0.1359 - accuracy: 0.9536 - val_loss: 0.2307 - val_accuracy: 0.9160\n",
      "Epoch 6/20\n",
      "178/178 [==============================] - 15s 84ms/step - loss: 0.1204 - accuracy: 0.9569 - val_loss: 0.1077 - val_accuracy: 0.9618\n",
      "Epoch 7/20\n",
      "178/178 [==============================] - 15s 84ms/step - loss: 0.0650 - accuracy: 0.9795 - val_loss: 0.2046 - val_accuracy: 0.9237\n",
      "Epoch 8/20\n",
      "178/178 [==============================] - 15s 84ms/step - loss: 0.0603 - accuracy: 0.9802 - val_loss: 0.0635 - val_accuracy: 0.9819\n",
      "Epoch 9/20\n",
      "178/178 [==============================] - 15s 84ms/step - loss: 0.0532 - accuracy: 0.9813 - val_loss: 0.2496 - val_accuracy: 0.9113\n",
      "Epoch 10/20\n",
      "178/178 [==============================] - 15s 84ms/step - loss: 0.0649 - accuracy: 0.9776 - val_loss: 0.0864 - val_accuracy: 0.9771\n",
      "Epoch 11/20\n",
      "178/178 [==============================] - 16s 88ms/step - loss: 0.0404 - accuracy: 0.9839 - val_loss: 0.1137 - val_accuracy: 0.9571\n",
      "Epoch 12/20\n",
      "178/178 [==============================] - 17s 95ms/step - loss: 0.0175 - accuracy: 0.9942 - val_loss: 0.2285 - val_accuracy: 0.9303\n",
      "Epoch 13/20\n",
      "178/178 [==============================] - 18s 99ms/step - loss: 0.0378 - accuracy: 0.9872 - val_loss: 0.0772 - val_accuracy: 0.9723\n",
      "Epoch 14/20\n",
      "178/178 [==============================] - 18s 99ms/step - loss: 0.0467 - accuracy: 0.9860 - val_loss: 0.0404 - val_accuracy: 0.9857\n",
      "Epoch 15/20\n",
      "178/178 [==============================] - 17s 97ms/step - loss: 0.0061 - accuracy: 0.9986 - val_loss: 0.1807 - val_accuracy: 0.9532\n",
      "Epoch 16/20\n",
      "178/178 [==============================] - 17s 95ms/step - loss: 0.0333 - accuracy: 0.9886 - val_loss: 0.0676 - val_accuracy: 0.9761\n",
      "Epoch 17/20\n",
      "178/178 [==============================] - 17s 97ms/step - loss: 0.0226 - accuracy: 0.9923 - val_loss: 0.0436 - val_accuracy: 0.9847\n",
      "Epoch 18/20\n",
      "178/178 [==============================] - 17s 97ms/step - loss: 0.0103 - accuracy: 0.9972 - val_loss: 0.0555 - val_accuracy: 0.9857\n",
      "Epoch 19/20\n",
      "178/178 [==============================] - 18s 98ms/step - loss: 0.0042 - accuracy: 0.9986 - val_loss: 0.0693 - val_accuracy: 0.9800\n",
      "Epoch 20/20\n",
      "178/178 [==============================] - 17s 95ms/step - loss: 0.0307 - accuracy: 0.9895 - val_loss: 0.1178 - val_accuracy: 0.9618\n"
     ]
    }
   ],
   "source": [
    "img_shape = (img_size[0], img_size[1], 3)\n",
    "model = Sequential(\n",
    "    [\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        Conv2D(  \n",
    "            filters=96,\n",
    "            kernel_size=(11, 11),\n",
    "            strides=(4, 4),\n",
    "            activation=\"relu\",\n",
    "            input_shape=img_shape,\n",
    "        ),\n",
    "        MaxPooling2D(pool_size=(3, 3), strides=(2, 2)),\n",
    "        Conv2D(\n",
    "            filters=256,\n",
    "            kernel_size=(5, 5),\n",
    "            strides=(1, 1),\n",
    "            activation=\"relu\",\n",
    "            padding=\"same\",\n",
    "        ),\n",
    "        MaxPooling2D(pool_size=(3, 3), strides=(2, 2)),\n",
    "        Conv2D(\n",
    "            filters=384,\n",
    "            kernel_size=(3, 3),\n",
    "            strides=(1, 1),\n",
    "            activation=\"relu\",\n",
    "            padding=\"same\",\n",
    "        ),\n",
    "        Conv2D(\n",
    "            filters=384,\n",
    "            kernel_size=(3, 3),\n",
    "            strides=(1, 1),\n",
    "            activation=\"relu\",\n",
    "            padding=\"same\",\n",
    "        ),\n",
    "        MaxPooling2D(pool_size=(3, 3), strides=(2, 2)),\n",
    "        Conv2D(\n",
    "            filters=384,\n",
    "            kernel_size=(3, 3),\n",
    "            strides=(1, 1),\n",
    "            activation=\"relu\",\n",
    "            padding=\"same\",\n",
    "        ),\n",
    "        Conv2D(\n",
    "            filters=256,\n",
    "            kernel_size=(3, 3),\n",
    "            strides=(1, 1),\n",
    "            activation=\"relu\",\n",
    "            padding=\"same\",\n",
    "        ),\n",
    "        MaxPooling2D(pool_size=(3, 3), strides=(2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(4096, activation=\"relu\"),\n",
    "        Dense(4096, activation=\"relu\"),\n",
    "        Dense(4, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=Adam(learning_rate=0.0001),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    steps_per_epoch=train_gen.samples / train_gen.batch_size,\n",
    "    validation_data=valid_gen,\n",
    "    epochs=20, \n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-14T06:46:45.542935195Z",
     "start_time": "2024-01-14T06:46:43.581929302Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 32ms/step - loss: 0.0255 - accuracy: 0.9863\n",
      "16/16 [==============================] - 1s 31ms/step - loss: 0.1132 - accuracy: 0.9648\n",
      " 9/16 [===============>..............] - ETA: 0s - loss: 0.2118 - accuracy: 0.9430WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 16 batches). You may need to use the repeat() function when building your dataset.\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 0.2118 - accuracy: 0.9430\n",
      "Train Loss:  0.025473223999142647\n",
      "Train Accuracy:  0.986328125\n",
      "--------------------\n",
      "Validation Loss:  0.11318159848451614\n",
      "Validation Accuracy:  0.96484375\n",
      "--------------------\n",
      "Test Loss:  0.21183985471725464\n",
      "Test Accuracy:  0.9429658055305481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-14 12:16:45.524368: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 16758032394245800167\n",
      "2024-01-14 12:16:45.524414: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 6343895248368649371\n",
      "2024-01-14 12:16:45.524436: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 9221365843799908292\n"
     ]
    }
   ],
   "source": [
    "train_score = model.evaluate(train_gen , steps =16 , verbose = 1)\n",
    "valid_score = model.evaluate(valid_gen , steps = 16 , verbose = 1)\n",
    "test_score = model.evaluate(test_gen , steps = 16 , verbose = 1)\n",
    "\n",
    "print(\"Train Loss: \", train_score[0])\n",
    "print(\"Train Accuracy: \", train_score[1])\n",
    "print('-' * 20)\n",
    "print(\"Validation Loss: \", valid_score[0])\n",
    "print(\"Validation Accuracy: \", valid_score[1])\n",
    "print('-' * 20)\n",
    "print(\"Test Loss: \", test_score[0])\n",
    "print(\"Test Accuracy: \", test_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-14T06:46:46.833872181Z",
     "start_time": "2024-01-14T06:46:45.542385746Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-14 12:16:46.313244: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 67108864 exceeds 10% of free system memory.\n",
      "2024-01-14 12:16:46.396187: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 67108864 exceeds 10% of free system memory.\n",
      "2024-01-14 12:16:46.426950: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 67108864 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ninetyheightdmodel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ninetyheightdmodel/assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"ninetyheightdmodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-14T06:46:46.837869601Z",
     "start_time": "2024-01-14T06:46:46.835113400Z"
    }
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(8,4))\n",
    "# plt.grid(True)\n",
    "# plt.plot(history.history['categorical_accuracy'], '.g-', linewidth=2)\n",
    "# plt.plot(history.history['loss'], '.r-', linewidth=2)\n",
    "# plt.title('Model Training History')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.xticks([x for x in range(10)])\n",
    "# plt.legend(['Accuracy', 'Loss'], loc='upper left', bbox_to_anchor=(1, 1))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-14T06:46:47.329448064Z",
     "start_time": "2024-01-14T06:46:46.839320695Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 32ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.92      0.96        61\n",
      "           1       0.90      0.87      0.89        63\n",
      "           2       0.92      1.00      0.96        79\n",
      "           3       0.97      0.97      0.97        60\n",
      "\n",
      "    accuracy                           0.94       263\n",
      "   macro avg       0.95      0.94      0.94       263\n",
      "weighted avg       0.94      0.94      0.94       263\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(test_gen)\n",
    "y_pred = np.argmax(preds , axis = 1)\n",
    "g_dict = test_gen.class_indices\n",
    "classes = list(g_dict.keys())\n",
    "print(classification_report(test_gen.classes,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-14T06:46:47.330168456Z",
     "start_time": "2024-01-14T06:46:47.329382463Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
